ğŸ“Œ Project Overview
This project automates the integration of fragmented retail data into a unified "Master Dataset." By merging transactional sales records with product metadata and shipping logistics, the pipeline creates a clean, enriched dataset suitable for Business Intelligence (BI) tools and predictive modeling.


ğŸ“‚ Data Architecture
The project utilizes four primary data components:

sales_data.csv: Transactional records containing Order_ID, Product_ID, Quantity, and Price.

product_info.csv: Dimensional data mapping Product_ID to its respective Category.

shipping_details.csv: Logistical data providing the Shipping_Cost for each Order_ID.

master_dataset.csv: The final output generated by the pipeline.


âš™ï¸ The ETL Pipeline (Python)The script Merging of datasets.py executes the following logic:Data Extraction: Loads the three source CSVs into Pandas DataFrames.Data Merging:Performs a Left Join between Sales and Product Info on Product_ID.Performs a Left Join between the result and Shipping Details on Order_ID.Feature Engineering:Derives a new column: Total_Revenue ($Quantity \times Price$).Data Loading: Exports the consolidated data to master_dataset.csv.


ğŸš€ Getting Started
Prerequisites
Ensure you have Python 3.x and the Pandas library installed:

Bash

pip install pandas
Installation & Execution
Clone this repository:

Bash

git clone https://github.com/yourusername/sales-data-integration.git
Navigate to the directory and run the pipeline:

Bash

python "Merging of datasets.py"


ğŸ“Š Analytical Potential
The generated master_dataset.csv allows for immediate analysis of:

Revenue Performance: Total sales value per product category.

Profitability Analysis: Net revenue after accounting for shipping costs.

Operational Trends: Order volume and revenue distribution over time.


ğŸ›  Technologies Used
Language: Python 3.x

Library: Pandas (Data Manipulation)

Environment: Jupyter Notebook / Python Script

Note: This project was developed as part of a data analysis workflow to demonstrate mastery in data merging, cleaning, and feature derivation.
