ğŸ“Œ Project OverviewThis project automates the integration of fragmented retail data into a unified "Master Dataset." By merging transactional sales records with product metadata and shipping logistics, the pipeline creates a clean, enriched dataset suitable for Business Intelligence (BI) tools and predictive modeling.ğŸ“‚ Data ArchitectureThe project utilizes four primary data components:sales_data.csv: Transactional records containing Order_ID, Product_ID, Quantity, and Price.product_info.csv: Dimensional data mapping Product_ID to its respective Category.shipping_details.csv: Logistical data providing the Shipping_Cost for each Order_ID.master_dataset.csv: The final output generated by the pipeline.âš™ï¸ The ETL Pipeline (Python)The script Merging of datasets.py executes the following logic:Data Extraction: Loads the three source CSVs into Pandas DataFrames.Data Merging:Performs a Left Join between Sales and Product Info on Product_ID.Performs a Left Join between the result and Shipping Details on Order_ID.Feature Engineering:Derives a new column: Total_Revenue ($Quantity \times Price$).Data Loading: Exports the consolidated data to master_dataset.csv.ğŸš€ Getting StartedPrerequisitesEnsure you have Python 3.x and the Pandas library installed:Bashpip install pandas
Installation & ExecutionClone this repository:Bashgit clone https://github.com/yourusername/sales-data-integration.git
Navigate to the directory and run the pipeline:Bashpython "Merging of datasets.py"
ğŸ“Š Analytical PotentialThe generated master_dataset.csv allows for immediate analysis of:Revenue Performance: Total sales value per product category.Profitability Analysis: Net revenue after accounting for shipping costs.Operational Trends: Order volume and revenue distribution over time.ğŸ›  Technologies UsedLanguage: Python 3.xLibrary: Pandas (Data Manipulation)Environment: Jupyter Notebook / Python ScriptNote: This project was developed as part of a data analysis workflow to demonstrate mastery in data merging, cleaning, and feature derivation.
